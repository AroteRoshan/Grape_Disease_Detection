{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5acf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501511ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf45a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=256\n",
    "CHANNELS=3\n",
    "EPOCHS=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f0e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4062 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "r\"C:\\Users\\tejas\\PycharmProjects\\GrapesDisease\\Grapes Data\\Grape\",\n",
    "shuffle=True,\n",
    "image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa5dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set image directory path and read images\n",
    "image_dir = r'C:\\Users\\tejas\\PycharmProjects\\GrapesDisease\\Grape'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for foldername in os.listdir(image_dir):\n",
    "    folderpath = os.path.join(image_dir, foldername)\n",
    "\n",
    "    if not os.path.isdir(folderpath):\n",
    "        continue\n",
    "    for filename in os.listdir(folderpath):\n",
    "        img = cv2.imread(os.path.join(folderpath, filename))\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        images.append(img)\n",
    "        if foldername == 'Healthy':\n",
    "            labels.append(0)\n",
    "        elif foldername == 'Black_rot':\n",
    "            labels.append(1)\n",
    "        elif foldername == 'Black_Measles':\n",
    "            labels.append(2)\n",
    "        elif foldername == 'Leaf_blight':\n",
    "            labels.append(3)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f86da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f1292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2599, 256, 256, 3)\n",
      "(650, 256, 256, 3)\n",
      "(2599,)\n",
      "(650,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac701033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b238ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 198s 2s/step - loss: 57.4857 - accuracy: 0.5214 - val_loss: 1.2765 - val_accuracy: 0.6062\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 194s 2s/step - loss: 1.1531 - accuracy: 0.4971 - val_loss: 1.1459 - val_accuracy: 0.5077\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 188s 2s/step - loss: 0.7164 - accuracy: 0.6987 - val_loss: 0.8307 - val_accuracy: 0.6554\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 214s 3s/step - loss: 0.4148 - accuracy: 0.8469 - val_loss: 0.5598 - val_accuracy: 0.7662\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 177s 2s/step - loss: 0.2076 - accuracy: 0.9254 - val_loss: 0.6248 - val_accuracy: 0.7477\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 177s 2s/step - loss: 0.1729 - accuracy: 0.9419 - val_loss: 0.7153 - val_accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 179s 2s/step - loss: 0.1165 - accuracy: 0.9592 - val_loss: 0.7167 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 180s 2s/step - loss: 0.0826 - accuracy: 0.9731 - val_loss: 0.5454 - val_accuracy: 0.8477\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 179s 2s/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.5974 - val_accuracy: 0.8477\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 180s 2s/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 1.1397 - val_accuracy: 0.8062\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00842b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 12s 444ms/step - loss: 1.2550 - accuracy: 0.8155\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4efa35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8154981732368469\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Deploy the model\n",
    "new_image = cv2.imread(r'C:\\Users\\tejas\\PycharmProjects\\GrapesDisease\\Grape\\Black_rot\\0d2c5ad5-1a2d-44f9-9be5-1aef9a51fb95___FAM_B.Rot 3469.JPG')\n",
    "new_image = cv2.resize(new_image,(256,256))\n",
    "new_image = np.array([new_image])\n",
    "pred = model.predict(new_image)[0]\n",
    "print('Predicted class:', np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b996f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=np.argmax(pred)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29927a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('grape_mod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82cdefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e07c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d1642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762aea51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedda9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b54f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c869034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b3386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9127c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3492b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57e462d9",
   "metadata": {},
   "source": [
    "# model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('AI_Grape.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41c138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ec1dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[201, 202, 212],\n",
       "        [198, 199, 209],\n",
       "        [194, 195, 205],\n",
       "        ...,\n",
       "        [188, 187, 197],\n",
       "        [186, 185, 195],\n",
       "        [183, 182, 192]],\n",
       "\n",
       "       [[198, 199, 209],\n",
       "        [197, 198, 208],\n",
       "        [195, 196, 206],\n",
       "        ...,\n",
       "        [188, 187, 197],\n",
       "        [189, 188, 198],\n",
       "        [187, 186, 196]],\n",
       "\n",
       "       [[196, 197, 207],\n",
       "        [196, 197, 207],\n",
       "        [196, 197, 207],\n",
       "        ...,\n",
       "        [187, 186, 196],\n",
       "        [189, 188, 198],\n",
       "        [187, 186, 196]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[177, 180, 194],\n",
       "        [182, 185, 199],\n",
       "        [187, 190, 204],\n",
       "        ...,\n",
       "        [183, 184, 198],\n",
       "        [190, 191, 205],\n",
       "        [191, 192, 206]],\n",
       "\n",
       "       [[148, 151, 165],\n",
       "        [156, 159, 173],\n",
       "        [166, 169, 183],\n",
       "        ...,\n",
       "        [185, 186, 200],\n",
       "        [188, 189, 203],\n",
       "        [187, 188, 202]],\n",
       "\n",
       "       [[100, 103, 117],\n",
       "        [111, 114, 128],\n",
       "        [126, 129, 143],\n",
       "        ...,\n",
       "        [188, 189, 203],\n",
       "        [183, 184, 198],\n",
       "        [177, 178, 192]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread('00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt-Copy1.N.V_HL 6067.JPG')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c27c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.resize(img,(224,224))\n",
    "img=img/255.0\n",
    "img=img.reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8f9e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 299ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a963b12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_arg=np.argmax(pred)\n",
    "pred_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6727a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=keras.models.load_model('grape_mod1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b127358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2=cv2.imread('00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt-Copy1.N.V_HL 6067.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095829e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2=cv2.resize(img2,(256,256))\n",
    "img2=img2/255.0\n",
    "img2=img2.reshape(1,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c2f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "pred2=model2.predict(img2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039ec7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_arg2=np.argmax(pred2)\n",
    "pred_arg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da1362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
